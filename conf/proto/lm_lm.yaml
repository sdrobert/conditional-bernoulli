model:
  conditional:
    embedding_size: 16  # The size of token embeddings.
    hidden_size: 128
    merge_method: mix # How to combine inputs with embeddings or hidden vectors. mix: softmax for weights then weighted mixture; cat: concatenate. Choices: "mix", "cat"
    num_layers: 3 # The number of LSTM layers.
lm:
  data:
    batch_size: 512
    drop_last: false
  training:
    dropout_prob: 0.3
    swap_prob: 0.3
    early_stopping_patience: 10
    early_stopping_threshold: 0.1